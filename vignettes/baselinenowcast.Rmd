---
title: "Getting Started with baselinenowcast"
description: "A quick start example demonstrating use of baselinenowcast"
output:
  bookdown::html_vignette2:
    fig_caption: yes
    code_folding: show
    fig_width: 8
    fig_height: 5
pkgdown:
  as_is: true
bibliography: library.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa-numeric-superscript-brackets.csl
link-citations: true
vignette: >
  %\VignetteIndexEntry{Getting Started with baselinenowcast}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\VignetteDepends{epinowcast, ggplot2, dplyr, tidyr}
---

# Introduction

Incomplete reporting of epidemiological data at recent times can result in case count data that is right-truncated.
Right-truncated case counts can be misleading to interpret at face-value, as they will typically show a decline in the number of reported observations in the most recent time points.
These are the time points where the highest proportion of the data has yet to be observed in the dataset.

The imputation of the cases that will eventually be observed up until the current time is referred to as a nowcast.

A number of methods have been developed to nowcast epidemiological case count data.

The purpose of `baselinenowcast` is to provide a nowcast computed directly from the most recent observations to estimate a delay distribution empirically, and apply that to the partially observed data to generate a nowcast.

In the below section, we will describe an example of a nowcasting problem, and demonstrate how to use the `baselinenowcast()` function to estimate a delay distribution from the data and apply that estimate to generate a probabilistic nowcast.
This function chains together a series of nowcasting steps.
For an example that walks through the low-level functionality applied to this same epidemiolical question, see the [modular workflow](modular_workflow.html) vignette.
In future vignettes, we will demonstrate examples of how to create more complex model permutations.
More details on the mathematical methods are provided in the [mathematical model](model_definition.html) vignette.

# Packages

As well as the `baselinenowcast` package this vignette also uses `epinowcast`, `ggplot2`, `tidyr`, and `dplyr`.
For `baselinenowcast`, see the [installation instructions](https://github.com/epinowcast/baselinenowcast#installation).

```{r setup2, message = FALSE, warning = FALSE, results = 'hide'}
library(baselinenowcast)
library(ggplot2)
library(dplyr)
library(tidyr)
```

# Data

Nowcasting of right-truncated case counts involves the estimation of reporting delays for recently reported data.
For this, we need case counts indexed both by when they were diagnosed (often called the "reference date") and by when they were reported (i.e. when administratively recorded via public health surveillance; often called "report date").
The difference between the reference date and the report date is the reporting delay.
For this quick start, we use daily level data from the [Robert Koch Institute via the Germany Nowcasting hub](https://github.com/KITmetricslab/hospitalization-nowcast-hub/wiki/Truth-data#role-an-definition-of-the-seven-day-hospitalization-incidence).
These data represent hospital admission counts by date of positive test and date of test report in Germany up to October 1, 2021.

We will filter the data to just look at the national-level data, for all age groups.
We will pretend that we are making a nowcast as of August 1, 2021, therefore we will exclude all reference dates and report dates from before that date.
`germany_covid19_hosp` is provided as package data, see `?germany_covid19_hosp` for details.
In this example, we will focus on the cases for all of Germany ("DE") summed across all age groups ("00+").
We'll start by preparing the data for nowcasting and evaluation by removing all reference dates beyond the nowcast date and report dates beyond the date we will use to evaluate our nowcast performance.

```{r}
nowcast_date <- "2021-08-01"
eval_date <- "2021-10-01"

target_data <- germany_covid19_hosp |>
  filter(
    location == "DE", age_group == "00+",
    report_date <= eval_date,
    reference_date <= nowcast_date
  )
```

Next we can plot both the "initial reports" by taking the sum of the cases at each reference date excluding all reports after the nowcast date, and compare that to what we will eventually observe as of the latest date in the complete dataset (data available through October 1, 2021).
Let's first take the sum of the cases at each reference date from the complete dataset, which represents the "final" case counts using the data available through October 1, 2021.
```{r}
latest_data <- target_data |>
  group_by(reference_date) |>
  summarise(count = sum(count))
```

Next, let's get a dataset of what we would have had available as of the nowcast date, which we obtain by excluding all report dates after the nowcast date.

```{r}
observed_data <- target_data |>
  filter(report_date <= nowcast_date)

head(observed_data)
```

We refer to the "initial reports" as the sum of the cases at each reference date as they were available as of the nowcast date.

```{r}
initial_reports <- observed_data |>
  group_by(reference_date) |>
  summarise(count = sum(count))
```

We will make a plot comparing the initial reports to the later observed final number of confirmed cases at each reference date.

<details><summary>Click to expand code to create the plot of the latest data</summary>

```{r}
plot_data <- ggplot() +
  geom_line(
    data = initial_reports,
    aes(x = reference_date, y = count), color = "darkred"
  ) +
  geom_line(
    data = latest_data,
    aes(x = reference_date, y = count), color = "black"
  ) +
  theme_bw() +
  xlab("Reference date") +
  ylab("Confirmed admissions") +
  scale_y_continuous(trans = "log10") +
  ggtitle("Comparing initially reported and later observed cases")
```
</details>
```{r}
plot_data
```

The red line shows the total number of confirmed admissions on each reference date, across all delays, using the data available as of August 1, 2021.
It demonstrates the characteristic behaviour of right-truncation.
This is because we have not yet observed the data with longer delays at recent time points.
The black line shows the total number of confirmed admissions on each reference date as of October 1, 2021.

Our task will be to estimate, from the data available up until August 1, 2021, the "final" number of cases at each reference date.

# Pre-processing

In order to compute a nowcast for this data, we will need to start by creating what we call a reporting triangle.
See the [nomenclature](nomenclature.html) vignette for more details on the structure and naming of different components used in the package.

The entries in the reporting triangle represent the number of new cases assigned to that reference time point with a particular delay, with entries in the bottom right of the triangle missing as the data reported with longer delays has yet to be observed for recent reference times.
The reporting triangle will be used to estimate the delay distribution, or the proportion of the final number of cases reported on a particular delay.

In this example, we will both fit our delay distribution, and apply it to generate a nowcast matrix using the same data, the national level data from Germany for all age groups.

We recommend choosing the maximum delay and number of historical observations based on an exploratory data analysis, as these specifications will change significantly depending on the dataset.
See the [NSSP nowcast](nssp_nowcast.html) for an example of an exploratory data analysis used to identify the maximum delay.
Here we will set the maximum delay to 30 days.

Empirical data outside this delay window will not be used for training.

```{r}
max_delay <- 30
```

Next, we will specify the amount of training volume used to fit the model as a function of the maximum delay, and the proportion of the total training volume used for delay estimation (with the remainder being used for uncertainty estimation).
Internally within `baselinenowcast()` we will call, `allocate_reference_times()` with these arguments.
We'll us the default settings for this function here, which uses 3 times the maximum delay for the total training volume with 50% used for delay estimation.

```{r}
scale_factor <- 3
prop_delay <- 0.5
```

Next we obtain a `reporting_triangle` using the `as_reporting_triangle()` function, which expects a data.frame with case counts indexed by reference date and report date and the maximum delay.
This function computes the delay between the reference and report date and pivots the data from long to wide, so that the rows are reference times and the columns indicate the delay between the reference and report date, and the entries indicate the incident case counts.
This also validates that the data is in the correct format and runs pre-processing to fill in any missing dates, see `?as_reporting_triangle.data.frame` and `?reporting_triangle` for more details on required inputs and the format of the `reporting_triangle` object.

```{r}
rep_tri <- as_reporting_triangle(observed_data,
  max_delay = max_delay
)
```

The `reporting_triangle` object is a matrix with named rows for the reference dates corresponding to each row of the matrix.

<details><summary>Click to expand code to create the plot of the reporting triangle</summary>
```{r}
triangle_df <- as.data.frame(rep_tri$reporting_triangle_matrix) |>
  mutate(time = row_number()) |>
  pivot_longer(!time,
    values_to = "count",
    names_prefix = "V",
    names_to = "delay"
  ) |>
  mutate(delay = as.numeric(delay))

plot_triangle <- ggplot(
  triangle_df,
  aes(x = delay, y = time, fill = count)
) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "Reporting triangle", x = "Delay", y = "Time") +
  theme_bw() +
  scale_y_reverse()
```
</details>

```{r}
plot_triangle
```
Here, the grey indicates matrix elements that are `NA`, which we would expect to be the case in the bottom right portion of the reporting triangle where the counts have yet to be observed.

# Run the `baselinenowcast` workflow

# Apply the delay to generate a point nowcast

The next step in our workflow is to take the estimated delay distribution and apply it to the partially observed reporting triangle, generating an estimate of the number of new cases confirmed at each reference date and delay.
This will generate a point estimate of complete the reporting matrix.
In this case, we will be applying the delay to the same reporting triangle we used to generate the estimate, but this doesn't always have to be the case.
See the documentation for `apply_delay()` for a full description of the input requirements.

It is worth noting that we could also have estimated the delay and applied it in one single step by calling `generate_pt_nowcast_mat()`.
In subsequent steps to estimate the uncertainty, both delay estimation and generating a point nowcast matrix happen in a single step.

```{r}
point_nowcast_matrix <- apply_delay(
  reporting_triangle = reporting_triangle,
  delay_pmf = delay_pmf
)
```

We'll make a quick plot to compare our point estimate of the nowcasted confirmed cases through August 1, 2021, to the "final" observations from October 1, 2021 and to the right-truncated data available up until August 1, 2021.

<details><summary>Click to expand code to create the plot of the point nowcast</summary>
```{r}
point_nowcast_df <- eval_data |>
  mutate(nowcast = rowSums(point_nowcast_matrix))

prep_latest_data <- latest_training_data |>
  mutate(type = "Real-time data") |>
  select(type, reference_date, count = confirm)
# Combine data into a single dataframe for plotting
plot_data <- point_nowcast_df |>
  pivot_longer(
    cols = c(confirm, nowcast),
    names_to = "type",
    values_to = "count"
  ) |>
  mutate(type = case_when(
    type == "confirm" ~ "Final observed data",
    type == "nowcast" ~ "Point nowcast",
    TRUE ~ type
  )) |>
  bind_rows(prep_latest_data)

# Create plot with data type as a variable
plot_pt_nowcast <- ggplot(plot_data, aes(
  x = reference_date,
  y = count,
  color = type
)) +
  geom_line() +
  scale_color_manual(values = c(
    "Real-time data" = "darkred",
    "Final observed data" = "black",
    "Point nowcast" = "darkblue"
  )) +
  theme_bw() +
  xlab("Reference date") +
  ylab("Confirmed admissions") +
  scale_y_continuous(trans = "log10") +
  ggtitle("Comparing real-time, nowcasted, and later observed cases") +
  theme(legend.position = "bottom") +
  labs(color = "Type")
```
</details>
```{r}
plot_pt_nowcast
```


Here we can see that our point nowcast (blue) slightly underestimates what was eventually reported (black), but does a decent overall job of correcting for the right-truncation observed in the the data as of the nowcast date (red).

# Estimate uncertainty

So far, we've demonstrated how to generate a point estimate of a nowcast.
We would like to generate probabilistic nowcasts.

The method used to estimate the uncertainty works by generating retrospective reporting triangles using what would have been available as of each retrospective nowcast time to estimate a delay distribution, generate a point nowcast matrix, and compare the estimated counts at each reference time to those that have been observed at each nowcast horizon.
It assumes that the observations follow a negative binomial observation model, and independently estimates the dispersion in the negative binomial at each forecast horizon.

We repeat this process for `n_retrospective_nowcasts` reference times in the current reporting triangle, starting from the latest reference time and working backwards, ultimately using all `n_retrospective_nowcasts` and `n_history_delay` reference times.


```{r}
trunc_rep_tri_list <- truncate_triangles(reporting_triangle,
  n = n_retrospective_nowcasts
)
retro_rep_tri_list <- construct_triangles(trunc_rep_tri_list)
```
This results in a list of retrospective reporting triangles.
See the documentation for `truncate_triangles()` and `construct_triangles()` for more information on the inputs and outputs of these functions.

Next we will pass this list of reporting triangles to the `fill_triangles()` and specify `n`, the number of reference times to be used to estimate the delay for each nowcast, which we will set as the `n_history_delay` previous specified.

```{r}
retro_pt_nowcast_mat_list <- fill_triangles(
  retro_reporting_triangles = retro_rep_tri_list,
  n = n_history_delay
)
```

Next, we will use the retrospective reporting triangles, the point nowcast matrices, and the truncated reporting triangles to estimate the uncertainty at each horizon, starting at horizon 0 using the `estimate_uncertainty()` function.


```{r}
disp_params <- estimate_uncertainty(
  point_nowcast_matrices = retro_pt_nowcast_mat_list,
  truncated_reporting_triangles = trunc_rep_tri_list,
  retro_reporting_triangles = retro_rep_tri_list,
  n = n_retrospective_nowcasts
)
```

# Generate probabilistic nowcast

Now that we have estimated the dispersion, we can generate a probabilistic nowcast using the `sample_nowcasts()` function which:

- generates draws from the nowcast distribution
- combines the draws with the observed data to form a single draw of the nowcast
- repeats this process for `draws` draws


```{r}
nowcast_draws_df <- sample_nowcasts(
  point_nowcast_matrix, reporting_triangle,
  uncertainty_params = disp_params,
  draws = 100
)

head(nowcast_draws_df)
```

See documentation for `sample_nowcasts()`for further details.

# Visualizing the nowcast

Let's visualize the nowcast compared to the final observed data.
We first need to join our nowcast with the original data so we can see our nowcast by reference date.

Prepare the data as of the nowcast date, `latest_training_data` so that we can map the nowcast draws onto it.

```{r}
latest_data_prepped <- latest_training_data |>
  mutate(time = row_number()) |>
  rename(obs_confirm = confirm) |>
  mutate(reference_date = as.Date(reference_date))
```

Prepare the final evaluation data so we can combine the datasets.

```{r}
final_data_prepped <- eval_data |>
  select(reference_date, final_confirm = confirm) |>
  mutate(reference_date = as.Date(reference_date))
```

Join the nowcasts, data as of the nowcast date, and the final data.

```{r}
obs_with_nowcast_draws_df <- nowcast_draws_df |>
  left_join(latest_data_prepped, by = "time") |>
  left_join(final_data_prepped, by = "reference_date")
head(obs_with_nowcast_draws_df)
```

Create a separate dataframe for only the observed and final data, to make plotting easier.

```{r}
combined_data <- obs_with_nowcast_draws_df |>
  select(reference_date, obs_confirm, final_confirm) |>
  distinct() |>
  pivot_longer(
    cols = c(obs_confirm, final_confirm),
    names_to = "type",
    values_to = "count"
  ) |>
  mutate(type = case_when(
    type == "obs_confirm" ~ "Observed data",
    type == "final_confirm" ~ "Final observed data"
  ))
```
<details><summary>Click to expand code to create the plot of the probabilistic nowcast</summary>
```{r}
# Plot with draws for nowcast only
plot_prob_nowcast <- ggplot() +
  # Add nowcast draws as thin gray lines
  geom_line(
    data = obs_with_nowcast_draws_df,
    aes(
      x = reference_date, y = pred_count, group = draw,
      color = "Nowcast draw", linewidth = "Nowcast draw"
    )
  ) +
  # Add observed data and final data once
  geom_line(
    data = combined_data,
    aes(
      x = reference_date,
      y = count,
      color = type,
      linewidth = type
    )
  ) +
  theme_bw() +
  scale_color_manual(
    values = c(
      "Nowcast draw" = "gray",
      "Observed data" = "darkred",
      "Final observed data" = "black"
    ),
    name = ""
  ) +
  scale_linewidth_manual(
    values = c(
      "Nowcast draw" = 0.2,
      "Observed data" = 1,
      "Final observed data" = 1
    ),
    name = ""
  ) +
  scale_y_continuous(trans = "log10") +
  xlab("Reference date") +
  ylab("Hospital admissions") +
  theme(legend.position = "bottom") +
  ggtitle("Comparison of admissions as of the nowcast date, later observed counts, \n and probabilistic nowcasted counts") # nolint
```
</details>
```{r}
plot_prob_nowcast
```


Gray lines indicate the probabilistic nowcast draws, which are a combination of the already observed data at each reference date and the predicted nowcast draws at each reference date.
Black lines show the "final" data from October 1, 2021.
